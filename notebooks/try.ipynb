{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "n_nodes = 10\n",
    "n_edges = 2\n",
    "seed = 1234\n",
    "N_SIM = 100c\n",
    "\n",
    "MEAN_RANGE = (-10, 10)\n",
    "STD_RANGE = (0.1, 5.0)\n",
    "MEAN_ERROR_RANGE = (0.02, 0.3)\n",
    "STD_ERROR_RANGE = (0.001, 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the first attempt in the Data Generation Process. \n",
    "\n",
    "To generate a network I used Barabasi-Albert model that is commonly used for modeling real-world systems, for instance friendhip groups or high school networks. It generates networks with a power-law degree distribution, resulting in some nodes have a much larger number of connections than others.\n",
    "\n",
    "To start with, we need to assume the type of network effect. Here I assume relational network effect, meaning that the outcome of te unit depends on its covariates, as well as their neighbours' outcome and covariates. There also could be a positional network effect, which depicts an effect on a network level, meaning that unit's position in network affects outcome and structural effect that depicts effect of the network as a whole. For simplicity I don't assume this. \n",
    "\n",
    "Additionally, we can simulate whether the influence of every node is the same by normalizing the adjacency matrix. Hovewer, in real-world scenarios I find this assumption too simplistic. \n",
    "\n",
    "To simulate these scenarios we can apply spatial lag model approaches. The value of the outcome of one unit depends on the value of its neighbours, leading to dependencies between neighbours. This means that a system of equations has to be solved simultaneously: $$ y = X\\beta + \\rho Wy + \\epsilon $$\n",
    "\n",
    "Solving for y:\n",
    "\n",
    "$$y = (I - \\rho W)^{-1}X\\beta + (I - \\rho W)^{-1}\\epsilon$$\n",
    "\n",
    "Then, we can simulate treatment $Z$, which results in the following model: $$y = (I - \\rho W)^{-1}X\\beta_{1} + (I - \\rho W)^{-1} (\\beta_{2}*Z) + (I - \\rho W)^{-1}\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_mean_std(n_features, mean_range=MEAN_RANGE, std_range=STD_RANGE):\n",
    "    means = np.random.uniform(mean_range[0], mean_range[1], n_features)\n",
    "    stds = np.random.uniform(std_range[0], std_range[1], n_features)\n",
    "    return means, stds\n",
    "\n",
    "def generate_random_beta_matrix(n_features):\n",
    "    means, stds = generate_random_mean_std(n_features)\n",
    "    beta = np.random.normal(means, stds, n_features)\n",
    "    return beta\n",
    "\n",
    "def generate_random_data(n_nodes, n_features):\n",
    "    means, stds = generate_random_mean_std(n_features)\n",
    "    data = np.zeros((n_nodes, n_features))\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        data[:, i] = np.random.normal(means[i], stds[i], n_nodes)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def generate_random_error(n_nodes, mean_range=MEAN_ERROR_RANGE, std_range=STD_ERROR_RANGE):\n",
    "    mean, std = generate_random_mean_std(n_features=1, mean_range=mean_range, std_range=std_range)\n",
    "    error = np.random.normal(mean, std, n_nodes)\n",
    "\n",
    "    return error\n",
    "\n",
    "def get_group_data(n_nodes, share_treatment=0.5, random=True, covariates=0):\n",
    "    if random:\n",
    "        pass\n",
    "    else:\n",
    "        n_treatment = int(n_nodes * share_treatment)\n",
    "        n_control = n_nodes - n_treatment \n",
    "        group = np.array([1] * n_treatment + [0] * n_control)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_outcome_SAR(\n",
    "    G,\n",
    "    n_nodes,\n",
    "    covariates,\n",
    "    betas,\n",
    "    epsilon,\n",
    "    neighbour_influence,\n",
    "    row_normalized=False,\n",
    "    group_data=0):\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    if row_normalized:\n",
    "        adj_matrix = adj_matrix / adj_matrix.sum(axis=1, keepdims=True)\n",
    "    I = np.eye(n_nodes)\n",
    "    weight = scipy.linalg.inv(I - neighbour_influence*adj_matrix)\n",
    "    if group_data:\n",
    "        y = weight@covariates@betas + weight@epsilon + weight@group_data*treatment_effect\n",
    "    else:\n",
    "        y = weight@covariates@betas + weight@epsilon\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_simulation(\n",
    "    n_sim,\n",
    "    n_nodes,\n",
    "    n_edges,\n",
    "    n_features,\n",
    "    mean_range_cov,\n",
    "    std_range_cov,\n",
    "    mean_range_error,\n",
    "    std_range_error,\n",
    "    share_treatment=0.5,\n",
    "    random=True,\n",
    "    seed=seed\n",
    "):\n",
    "    outcome_dict = {i: [] for i in n_sim}\n",
    "    for i in n_sim:\n",
    "        G = nx.barabasi_albert_graph(n=n_nodes, m=n_edges, seed=seed)\n",
    "        means, stds = generate_random_mean_std(n_features, mean_range=mean_range_cov, std_range=std_range_cov)\n",
    "        betas = generate_random_beta_matrix(n_features)\n",
    "        data = generate_random_data(n_nodes, n_features)\n",
    "        error = generate_random_error(n_nodes, mean_range=mean_range_error, std_range=std_range_error)\n",
    "        group_assignment = get_group_data(n_nodes, share_treatment=0.5, random=True, covariates=0)\n",
    "        outcome = define_outcome_SAR(\n",
    "            G,\n",
    "            n_nodes,\n",
    "            covariates,\n",
    "            betas,\n",
    "            epsilon,\n",
    "            neighbour_influence,\n",
    "            group_assignment)\n",
    "        outcome_dict[i] = outcome\n",
    "    \n",
    "    return outcome"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treatment assignment also can differs. For example, it can be random but as we are modelling observational study, this assumption don't apply. I assume that the treatment of the unit depends on its covariates. There are several ways to model this, using logistic regression model or some linear threshold. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. Simulate different treatment assignments\n",
    "2. Simulate effect estimation: naive, matching\n",
    "3. Add time "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_networks",
   "language": "python",
   "name": "causal_networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
